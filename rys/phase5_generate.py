#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 5: Script Generation (v2.13)
Generates bash scripts for jobs based on the I/O plan in TOON format.
Updated: Renamed REQUEST to Job (v2.13)
"""

import sys
import os
import json
import argparse
from phase_utils import invoke_coder, prepare_coder_prompt, append_result_display

# pylint: disable=useless-return

# Add project root to path for utilities
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
if SCRIPT_DIR not in sys.path:
    sys.path.append(SCRIPT_DIR)


def get_capture_glue(output_type):
    """Returns the capture glue based on output type."""
    if output_type == "list":
        return "| mapfile -t script_output"
    # Default to multi-line safe capture for Value, Path, Content, etc.
    return "| read -r -d '' script_output || true"


def process_single_job(job, args, llm_config):
    """Processes one job: codes tasks and writes the script."""
    job_id = job["job_id"]
    skill = job["skill"]

    print(f"Handling {job_id} ({skill})...")
    # --- Framework Setup (etude_test.bash style) ---
    script_lines = [
        "#!/bin/bash",
        "# Generated by RYS Phase 5",
        "set -euo pipefail",
        "set +m",
        "shopt -s lastpipe",
        ""
    ]
    
    final_binding = None
    first_task = True

    for task in job["tasks"]:
        # --- Framework Glue: Input Preparation ---
        if first_task:
            in_data = task.get("input", {})
            in_val = in_data.get("value", "./")
            if in_data.get("type") == "None" or in_val is None:
                script_lines.append("# Framework: No input required for first task")
                script_lines.append("input=\"\"")
            else:
                script_lines.append(f"input=\"{in_val}\"")
            
            # Handle Parameters (e.g., input_filename)
            params = in_data.get("params", {})
            for k, v in params.items():
                script_lines.append(f"input_{k}=\"{v}\"")
                
            first_task = False
        else:
            # Transfer previous output to current input
            if not task.get("loop"):
                # Smart transition: If previous output was a list, convert to multi-line string
                prev_task = job["tasks"][job["tasks"].index(task)-1]
                if prev_task.get("output", {}).get("type") == "list":
                    script_lines.append("inputs=(\"${script_output[@]}\")")
                    script_lines.append("input=$(printf \"%s\\n\" \"${inputs[@]}\")")
                else:
                    script_lines.append("input=\"${script_output}\"")
            
            # Handle parameters even for non-first tasks if any
            params = task.get("input", {}).get("params", {})
            for k, v in params.items():
                script_lines.append(f"input_{k}=\"{v}\"")
        
        print(f"  Coding {task['id']}...")
        prompt = prepare_coder_prompt(task)
        snippet = invoke_coder(SCRIPT_DIR, prompt, skill, llm_config)
        
        script_lines.append(f"# --- {task['id']}: {task['title']} ---")
        
        # Determine output capture glue
        out_type = task.get("output", {}).get("type", "string").lower()
        capture_glue = get_capture_glue(out_type)

        if task.get("loop"):
            # Framework: Loop Architecture
            script_lines.append("inputs=(\"${script_output[@]}\")")
            script_lines.append("for input in \"${inputs[@]}\"; do")
            indented_snippet = "\n".join(["  " + l for l in snippet.splitlines()])
            script_lines.append(indented_snippet)
            script_lines.append(f"done {capture_glue}")
        else:
            # Single task: Snippet + Capture
            # Use block wrapping for multi-line snippets or specific scripts
            if "\n" in snippet or snippet.strip().startswith("python3"):
                script_lines.append("{")
                indented_snippet = "\n".join(["  " + l for l in snippet.splitlines()])
                script_lines.append(indented_snippet)
                script_lines.append(f"}} {capture_glue}")
            else:
                script_lines.append(f"{snippet} {capture_glue}")
        
        # --- Framework Glue: Output Binding ---
        binding = task.get('output', {}).get('binding')
        if binding:
            script_lines.append(f"{binding}=\"${{script_output}}\"")
            final_binding = binding
        
        script_lines.append("")

    append_result_display(script_lines, job_id, final_binding)

    cache_dir = os.environ.get("RYS_CACHE_DIR", "./tmp")
    script_fn = f".rys.{args.uuid}.{job_id}.sh"
    script_path = os.path.abspath(os.path.join(cache_dir, script_fn))

    with open(script_path, "w", encoding="utf-8") as f_out:
        f_out.write("\n".join(script_lines))
    os.chmod(script_path, 0o755)

    return {"job_id": job_id, "path": script_path, "skill": skill}


def load_existing_scripts(out_json):
    """Loads previously generated scripts from output JSON."""
    existing = {}
    if os.path.exists(out_json):
        try:
            with open(out_json, 'r', encoding='utf-8') as f_in:
                old_data = json.load(f_in)
                for script in old_data.get("generated_scripts", []):
                    existing[script["job_id"]] = script
        except (json.JSONDecodeError, KeyError, OSError):
            pass
    return existing


def main():
    """Main execution for Phase 5 script generation."""
    parser = argparse.ArgumentParser()
    parser.add_argument("--in-json", required=True)
    parser.add_argument("--out-json", required=True)
    parser.add_argument("--uuid", required=True)
    parser.add_argument("--host", default="localhost")
    parser.add_argument("--port")
    parser.add_argument("--model", default="gemma3n:e4b")
    parser.add_argument("--job", "--request", help="Specific Job ID to regenerate")
    args = parser.parse_args()

    if not os.path.exists(args.in_json):
        sys.exit(1)

    with open(args.in_json, 'r', encoding='utf-8') as f_in:
        data = json.load(f_in)

    llm_config = {"host": args.host, "port": args.port, "model": args.model}
    existing_scripts = load_existing_scripts(args.out_json)
    script_list = []

    print(f">>> Phase 5: Generating Scripts (Session: {args.uuid})")

    for job in data.get("integrated_jobs", []):
        job_id = job["job_id"]
        if job["skill"] == "IDONTKNOW":
            continue

        if args.job and job_id != args.job:
            if job_id in existing_scripts:
                print(f"Skipping {job_id} (Keeping existing script)")
                script_list.append(existing_scripts[job_id])
            continue

        script_list.append(process_single_job(job, args, llm_config))

    data["generated_scripts"] = script_list
    with open(args.out_json, "w", encoding="utf-8") as f_out:
        json.dump(data, f_out, indent=2)

    print(f"Phase 5 Complete. {len(script_list)} scripts tracked.\n")
    return


if __name__ == "__main__":
    main()
